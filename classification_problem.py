# -*- coding: utf-8 -*-
"""Classification_problem.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VmbxWUO26M_Xu7ATWuiFipNhdRK1Xxwg

#A
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv('/content/drive/MyDrive/weather_forecast_data.csv')

data.info()

data.head()

data.describe()

data.isnull().sum()

data.duplicated().sum()

fig, axes = plt.subplots(2, 3, figsize=(18, 10))
fig.suptitle('Distribution of Numerical Features')

sns.histplot(data['Temperature'], kde=True, ax=axes[0, 0])
axes[0, 0].set_title('Temperature')

sns.histplot(data['Humidity'], kde=True, ax=axes[0, 1])
axes[0, 1].set_title('Humidity')

sns.histplot(data['Wind_Speed'], kde=True, ax=axes[0, 2])
axes[0, 2].set_title('Wind Speed')

sns.histplot(data['Cloud_Cover'], kde=True, ax=axes[1, 0])
axes[1, 0].set_title('Cloud Cover')

sns.histplot(data['Pressure'], kde=True, ax=axes[1, 1])
axes[1, 1].set_title('Pressure')

# Distribution of Rain (target variable)
sns.countplot(data=data, x='Rain', ax=axes[1, 2])
axes[1, 2].set_title('Rain Distribution')

plt.tight_layout()
plt.show()

def assign_weather_condition(row):
    if row['Temperature'] > 25 and row['Cloud_Cover'] < 30 and row['Humidity'] < 60:
        return 'Sunny'
    elif row['Cloud_Cover'] > 50 and row['Humidity'] > 60:
        return 'Rainy'
    else:
        return 'Cloudy'


data['WeatherCondition'] = data.apply(assign_weather_condition, axis=1)

data.head()

data.info()

data.drop(columns=['Rain'])

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
sns.countplot(x='WeatherCondition', data=data, palette='Set2')
plt.title('Distribution of WeatherCondition')
plt.xlabel('Weather Condition')
plt.ylabel('Count')
plt.show()


numeric_columns = data.select_dtypes(include=['float64', 'int64']).columns


sns.pairplot(data[numeric_columns.tolist() + ['WeatherCondition']], hue='WeatherCondition', palette='Set2')
plt.suptitle('Pairplot of Features by WeatherCondition', y=1.02)
plt.show()


plt.figure(figsize=(10, 6))
sns.boxplot(x='WeatherCondition', y='Temperature', data=data, palette='Set2')
plt.title('Temperature Distribution by WeatherCondition')
plt.show()

plt.figure(figsize=(10, 6))
corr = data[numeric_columns].corr()  # Calculate correlation matrix
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()

from sklearn.utils import resample
import pandas as pd

# Print the count of each category in the 'WeatherCondition' column
print(data['WeatherCondition'].value_counts())

# Filter the original dataset into separate DataFrames based on 'WeatherCondition'
sunny_data = data[data['WeatherCondition'] == 'Sunny']
cloudy_data = data[data['WeatherCondition'] == 'Cloudy']
rainy_data = data[data['WeatherCondition'] == 'Rainy']

# Upsample the 'Sunny' category to match the number of samples in the 'Cloudy' category
sunny_upsampled = resample(sunny_data,
                           replace=True,  # Sample with replacement
                           n_samples=len(cloudy_data),  # Match the size of 'Cloudy' category
                           random_state=42)  # Ensure reproducibility

# Upsample the 'Rainy' category to match the number of samples in the 'Cloudy' category
rainy_upsampled = resample(rainy_data,
                           replace=True,  # Sample with replacement
                           n_samples=len(cloudy_data),  # Match the size of 'Cloudy' category
                           random_state=42)  # Ensure reproducibility

# Combine the upsampled and original 'Cloudy' data to create a balanced dataset
data_balanced = pd.concat([sunny_upsampled, cloudy_data, rainy_upsampled])

# Shuffle the balanced dataset and reset the index
data_balanced = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)

# Print the count of each category in the balanced dataset to verify the results
print(data_balanced['WeatherCondition'].value_counts())

data_balanced.info()

# Import necessary libraries for visualization
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Visualizing the distribution of WeatherCondition (Bar plot) with the balanced dataset
plt.figure(figsize=(8, 6))
sns.countplot(x='WeatherCondition', data=data_balanced, palette='Set2')
plt.title('Distribution of WeatherCondition (Balanced Data)')
plt.xlabel('Weather Condition')
plt.ylabel('Count')
plt.show()

# 2. Pairplot to visualize relationships between features and WeatherCondition
# We need to select numeric columns from the balanced dataset for the pairplot
numeric_columns = data_balanced.select_dtypes(include=['float64', 'int64']).columns

# Add the target 'WeatherCondition' to the numeric columns for visualization
sns.pairplot(data_balanced[numeric_columns.tolist() + ['WeatherCondition']], hue='WeatherCondition', palette='Set2')
plt.suptitle('Pairplot of Features by WeatherCondition (Balanced Data)', y=1.02)
plt.show()

# 3. Box plot to check the distribution of numerical features across different weather conditions
# Example: Visualize the distribution of Temperature across different weather conditions in the balanced data
plt.figure(figsize=(10, 6))
sns.boxplot(x='WeatherCondition', y='Temperature', data=data_balanced, palette='Set2')
plt.title('Temperature Distribution by WeatherCondition (Balanced Data)')
plt.show()

# 4. Correlation heatmap for the numerical features in the balanced dataset
# This helps to see correlations between features and target (if features are numeric)
plt.figure(figsize=(10, 6))
corr = data_balanced[numeric_columns].corr()  # Calculate correlation matrix for balanced data
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Heatmap of Numerical Features (Balanced Data)')
plt.show()

data_balanced.drop(columns=['Rain'])

# Import necessary libraries for modeling
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

# Prepare Features (X) and Target (y)
X = data_balanced.drop(columns=['WeatherCondition','Rain'])
y = data_balanced['WeatherCondition']

# Split the balanced data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scaling the features (important for SVM and KNN)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# KNN Classifier
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)

# Predict on test data
y_pred_knn = knn.predict(X_test_scaled)

#  SVM Classifier
svm = SVC(kernel='linear')
svm.fit(X_train_scaled, y_train)

# Predict on test data
y_pred_svm = svm.predict(X_test_scaled)

# Step 6: Evaluate both models
# KNN Evaluation
print("KNN Model Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn)}")
print(classification_report(y_test, y_pred_knn))

# SVM Evaluation
print("SVM Model Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm)}")
print(classification_report(y_test, y_pred_svm))

from sklearn.model_selection import GridSearchCV

# Hyperparameter tuning for KNN
knn_params = {
    'n_neighbors': [3, 5, 7, 9],
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# Setup GridSearchCV for KNN
knn_grid_search = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=knn_params, cv=5, n_jobs=-1, scoring='accuracy')
knn_grid_search.fit(X_train_scaled, y_train)

# Best KNN parameters and performance
print("Best KNN Parameters:", knn_grid_search.best_params_)
print("Best KNN Accuracy on Training Data:", knn_grid_search.best_score_)

# Predict with the best KNN model
y_pred_knn_tuned = knn_grid_search.predict(X_test_scaled)

# KNN Evaluation
print("Tuned KNN Model Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn_tuned)}")
print(classification_report(y_test, y_pred_knn_tuned))

# Hyperparameter tuning for SVM
svm_params = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto']
}

# Setup GridSearchCV for SVM
svm_grid_search = GridSearchCV(estimator=SVC(), param_grid=svm_params, cv=5, n_jobs=-1, scoring='accuracy')
svm_grid_search.fit(X_train_scaled, y_train)

# Best SVM parameters and performance
print("Best SVM Parameters:", svm_grid_search.best_params_)
print("Best SVM Accuracy on Training Data:", svm_grid_search.best_score_)

# Predict with the best SVM model
y_pred_svm_tuned = svm_grid_search.predict(X_test_scaled)

# SVM Evaluation
print("Tuned SVM Model Performance:")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm_tuned)}")
print(classification_report(y_test, y_pred_svm_tuned))

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize the predicted vs. actual weather conditions
plt.figure(figsize=(8, 6))
sns.countplot(x=y_test, hue=y_pred_knn_tuned, palette='Set2')
plt.title('Predicted vs. Actual Weather Condition (Tuned KNN)')
plt.xlabel('Actual Weather Condition')
plt.ylabel('Count')
plt.show()


from sklearn.metrics import confusion_matrix

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_knn_tuned)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Cloudy', 'Rainy', 'Sunny'],
            yticklabels=['Cloudy', 'Rainy', 'Sunny'])
plt.title('Confusion Matrix (Tuned KNN)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()


plt.figure(figsize=(8, 6))
sns.countplot(x=y_test, hue=y_pred_svm_tuned, palette='Set2')
plt.title('Predicted vs. Actual Weather Condition (Tuned SVM)')
plt.xlabel('Actual Weather Condition')
plt.ylabel('Count')
plt.show()


from sklearn.metrics import confusion_matrix

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_svm_tuned)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Cloudy', 'Rainy', 'Sunny'],
            yticklabels=['Cloudy', 'Rainy', 'Sunny'])
plt.title('Confusion Matrix (Tuned SVM)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()